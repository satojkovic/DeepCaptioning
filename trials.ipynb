{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import JSON\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('flickr8k/dataset.json', 'r') as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data['images'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(json_data['images'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth image descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt_image_descriptions(json_data):\n",
    "    descriptions = defaultdict(list)\n",
    "    for jd in json_data['images']:\n",
    "        fn = jd['filename'].split('.')[0]\n",
    "        for s in jd['sentences']:\n",
    "            descriptions[fn].append(s['raw'])\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = get_gt_image_descriptions(json_data)\n",
    "sample_image_id = np.random.choice(list(descriptions.keys()))\n",
    "print('\\n'.join(descriptions[sample_image_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_descriptions(descriptions):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for key, desc_list in descriptions.items():\n",
    "        for i in range(len(desc_list)):\n",
    "            desc = desc_list[i]\n",
    "            # tokenize\n",
    "            desc = desc.split()\n",
    "            # convert to lower case\n",
    "            desc = [w.lower() for w in desc]\n",
    "            # remove punctuation\n",
    "            desc = [w.translate(table) for w in desc]\n",
    "            # remove 'a' and 's'\n",
    "            desc = [w for w in desc if len(w) > 1]\n",
    "            # remove tokens with numbers in them\n",
    "            desc = [w for w in desc if w.isalpha()]\n",
    "            # store as string\n",
    "            desc_list[i] = ' '.join(desc)\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_descriptions = clean_descriptions(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_descriptions[sample_image_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_descriptions = [len(clean_descriptions[key]) for key in clean_descriptions.keys()]\n",
    "print(sum(all_descriptions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(clean_descriptions):\n",
    "    #  remove duplicate words (set of unique words)\n",
    "    vocabulary = set()\n",
    "    for key in clean_descriptions.keys():\n",
    "        [vocabulary.update(d.split()) for d in clean_descriptions[key]]\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = create_vocabulary(clean_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('vocabulary size:', len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_descriptions(clean_descriptions, filename):\n",
    "    lines = []\n",
    "    for key, desc_list in clean_descriptions.items():\n",
    "        for desc in desc_list:\n",
    "            lines.append(key + ' ' + desc)\n",
    "    with open(filename, 'w') as f:\n",
    "        for line in lines:\n",
    "            f.writelines(line)\n",
    "            f.writelines('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_descriptions(clean_descriptions, 'descriptions.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean_desc_keys, test_clean_desc_keys = train_test_split(list(clean_descriptions.keys()))\n",
    "print('train size:', len(train_clean_desc_keys))\n",
    "print('test size:', len(test_clean_desc_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_clean_descriptions(train_clean_desc_keys, filename):\n",
    "    train_clean_descriptions = {}\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            tokens = line.split()\n",
    "            image_id, image_desc = tokens[0], tokens[1:]\n",
    "            # skip images not in the train set\n",
    "            if image_id in train_clean_desc_keys:\n",
    "                if not image_id in train_clean_descriptions:\n",
    "                    train_clean_descriptions[image_id] = []\n",
    "                # add start and end token\n",
    "                desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
    "                train_clean_descriptions[image_id].append(desc)\n",
    "    return train_clean_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_descriptions = load_train_clean_descriptions(train_clean_desc_keys, 'descriptions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Descriptions: train={}'.format(len(train_descriptions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_descriptions[sample_image_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Vector Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionV3(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.input)\n",
    "print(model.layers[-2:])\n",
    "print(model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = Model(model.input, model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_path):\n",
    "    # convert all images to the size 299x299 as expected by the Inception v3\n",
    "    img = image.load_img(image_path, target_size=(299, 299))\n",
    "    # convert PIL image to numpy array\n",
    "    x = image.img_to_array(img)\n",
    "    # Add one more dimension\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    # preprocess image using preprocess_input from inception_v3 module\n",
    "    x = preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "def encode(img):\n",
    "    img = preprocess(img)\n",
    "    feat_vec = model_new.predict(img)\n",
    "    feat_vec = np.reshape(feat_vec, feat_vec.shape[1])\n",
    "    return feat_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'flickr8k/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "encoding_train = {}\n",
    "for base_img_fn in train_clean_desc_keys:\n",
    "    img_fn = base_img_fn + '.jpg'\n",
    "    image_file_path = os.path.abspath(os.path.join(image_dir, img_fn))\n",
    "    if not os.path.exists(image_file_path):\n",
    "        print('Not found image:', image_file_path)\n",
    "        continue\n",
    "    encoding_train[base_img_fn] = encode(os.path.join(image_dir, img_fn))\n",
    "print('encoding time for train:', time() - start)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"encoded_train_images.pkl\", \"wb\") as f:\n",
    "  pickle.dump(encoding_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "encoding_test = {}\n",
    "for i, base_img_fn in enumerate(test_clean_desc_keys):\n",
    "    img_fn = base_img_fn + '.jpg'\n",
    "    image_file_path = os.path.abspath(os.path.join(image_dir, img_fn))\n",
    "    if not os.path.exists(image_file_path):\n",
    "        print('Not found image:', image_file_path)\n",
    "        continue\n",
    "    else:\n",
    "        print('{}: {}'.format(i, img_fn))\n",
    "    encoding_test[base_img_fn] = encode(os.path.join(image_dir, img_fn))\n",
    "print('encoding time for test:', time() - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"encoded_test_images.pkl\", \"wb\") as f:\n",
    "  pickle.dump(encoding_test, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
